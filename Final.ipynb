{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4212522-11cc-4003-9ee8-0dcf86987312",
   "metadata": {},
   "source": [
    "**Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7d58940-5edc-4cbe-a898-212af9eac2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python-headless in c:\\python311\\lib\\site-packages (4.8.1.78)\n",
      "Requirement already satisfied: numpy in c:\\python311\\lib\\site-packages (1.26.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python-headless numpy --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ecfe44-10c2-4fdf-b1ca-21c35860be1e",
   "metadata": {},
   "source": [
    "**Splitting The DataSet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4aef4f26-ad8b-499c-aec0-4c5701a22915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split and copied successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Define the paths to your dataset folders\n",
    "dataset_dir = \"dataset\"  # Update this to the correct path\n",
    "training_dir = \"training\"\n",
    "testing_dir = \"testing\"\n",
    "validating_dir = \"validating\"\n",
    "\n",
    "# Define the ratio for splitting (80% training, 10% testing, 10% validating)\n",
    "train_ratio = 0.8\n",
    "test_ratio = 0.1\n",
    "valid_ratio = 0.1\n",
    "\n",
    "# Create the destination folders if they don't exist\n",
    "os.makedirs(training_dir, exist_ok=True)\n",
    "os.makedirs(testing_dir, exist_ok=True)\n",
    "os.makedirs(validating_dir, exist_ok=True)\n",
    "\n",
    "# Iterate through the \"car\" and \"notcar\" folders\n",
    "categories = [\"car\", \"notcar\"]\n",
    "for category in categories:\n",
    "    category_dir = os.path.join(dataset_dir, category)  # Construct the full path to the category folder\n",
    "    \n",
    "    # Create subdirectories in the destination folders for \"car\" and \"notcar\"\n",
    "    os.makedirs(os.path.join(training_dir, category), exist_ok=True)\n",
    "    os.makedirs(os.path.join(testing_dir, category), exist_ok=True)\n",
    "    os.makedirs(os.path.join(validating_dir, category), exist_ok=True)\n",
    "    \n",
    "    # Get a list of all image files in the category folder\n",
    "    image_files = os.listdir(category_dir)\n",
    "    \n",
    "    # Shuffle the image files randomly\n",
    "    random.shuffle(image_files)\n",
    "    \n",
    "    # Calculate the number of images for each split\n",
    "    num_images = len(image_files)\n",
    "    num_train = int(num_images * train_ratio)\n",
    "    num_test = int(num_images * test_ratio)\n",
    "    \n",
    "    # Split the images into training, testing, and validating sets\n",
    "    train_images = image_files[:num_train]\n",
    "    test_images = image_files[num_train:num_train + num_test]\n",
    "    valid_images = image_files[num_train + num_test:]\n",
    "    \n",
    "    # Copy the images to their respective folders\n",
    "    for image in train_images:\n",
    "        src = os.path.join(category_dir, image)\n",
    "        dst = os.path.join(training_dir, category, image)\n",
    "        shutil.copy(src, dst)\n",
    "    \n",
    "    for image in test_images:\n",
    "        src = os.path.join(category_dir, image)\n",
    "        dst = os.path.join(testing_dir, category, image)\n",
    "        shutil.copy(src, dst)\n",
    "    \n",
    "    for image in valid_images:\n",
    "        src = os.path.join(category_dir, image)\n",
    "        dst = os.path.join(validating_dir, category, image)\n",
    "        shutil.copy(src, dst)\n",
    "\n",
    "print(\"Data split and copied successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd83d5de-12f6-4a9f-8a9a-a7ddbde8a1de",
   "metadata": {},
   "source": [
    "**Training the Data() Version 1**\n",
    "*This doesnt save the model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b7469d2-3c4b-4acb-aa62-99fbac413e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Training time: 14.19 seconds\n",
      "Efficiency: 0.54\n",
      "\n",
      "Epoch 2/10\n",
      "Training time: 6.16 seconds\n",
      "Efficiency: 0.62\n",
      "\n",
      "Epoch 3/10\n",
      "Training time: 5.98 seconds\n",
      "Efficiency: 0.69\n",
      "\n",
      "Epoch 4/10\n",
      "Training time: 6.08 seconds\n",
      "Efficiency: 0.72\n",
      "\n",
      "Epoch 5/10\n",
      "Training time: 6.22 seconds\n",
      "Efficiency: 0.75\n",
      "\n",
      "Epoch 6/10\n",
      "Training time: 5.95 seconds\n",
      "Efficiency: 0.79\n",
      "\n",
      "Epoch 7/10\n",
      "Training time: 6.05 seconds\n",
      "Efficiency: 0.79\n",
      "\n",
      "Epoch 8/10\n",
      "Training time: 6.25 seconds\n",
      "Efficiency: 0.81\n",
      "\n",
      "Epoch 9/10\n",
      "Training time: 6.34 seconds\n",
      "Efficiency: 0.82\n",
      "\n",
      "Epoch 10/10\n",
      "Training time: 6.63 seconds\n",
      "Efficiency: 0.84\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Function to extract HOG features from an image\n",
    "def extract_features(image_path, fixed_length):\n",
    "    # Load the image and resize it to a smaller size\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    image = cv2.resize(image, (64, 128))  # Resize to a smaller size\n",
    "    \n",
    "    # Extract HOG features with reduced dimensionality\n",
    "    hog = cv2.HOGDescriptor((64, 64), (16, 16), (8, 8), (8, 8), 9)\n",
    "    features = hog.compute(image)\n",
    "    \n",
    "    # Convert the tuple to a NumPy array and then flatten\n",
    "    features = np.array(features)\n",
    "    features = features.flatten()\n",
    "    \n",
    "    # Resize features to a fixed length\n",
    "    if len(features) < fixed_length:\n",
    "        features = np.pad(features, (0, fixed_length - len(features)))\n",
    "    elif len(features) > fixed_length:\n",
    "        features = features[:fixed_length]\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Perceptron class for binary classification\n",
    "class Perceptron:\n",
    "    def __init__(self, num_features):\n",
    "        self.weights = np.random.rand(num_features)\n",
    "        self.bias = np.random.rand()\n",
    "    \n",
    "    def predict(self, features):\n",
    "        activation = np.dot(features, self.weights) + self.bias\n",
    "        return 1 if activation > 0 else 0\n",
    "    \n",
    "    def train(self, features, label, learning_rate=0.01):\n",
    "        if len(features) != len(self.weights):\n",
    "            raise ValueError(\"Number of features must match the number of weights\")\n",
    "        \n",
    "        prediction = self.predict(features)\n",
    "        error = label - prediction\n",
    "        self.weights += learning_rate * error * features\n",
    "        self.bias += learning_rate * error\n",
    "\n",
    "# Path to the training data folders (car and not_car)\n",
    "car_folder = \"training/car\"\n",
    "not_car_folder = \"training/car\"\n",
    "\n",
    "# Initialize the perceptron\n",
    "fixed_length = 1000  # Adjust this value based on your needs\n",
    "num_features = fixed_length\n",
    "perceptron = Perceptron(num_features)\n",
    "\n",
    "# Training loop\n",
    "epochs = 10  # Adjust the number of epochs as needed\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    correct_predictions = 0\n",
    "    total_images = 0\n",
    "    \n",
    "    # Training on car images\n",
    "    for image_name in os.listdir(car_folder):\n",
    "        image_path = os.path.join(car_folder, image_name)\n",
    "        features = extract_features(image_path, fixed_length)\n",
    "        perceptron.train(features, 1)  # Label 1 for car images\n",
    "        prediction = perceptron.predict(features)\n",
    "        if prediction == 1:\n",
    "            correct_predictions += 1\n",
    "        total_images += 1\n",
    "\n",
    "        # Training on not car images (alternating between car and not car)\n",
    "        no_car_image_name = os.listdir(not_car_folder)[total_images % len(os.listdir(not_car_folder))]\n",
    "        no_car_image_path = os.path.join(not_car_folder, no_car_image_name)\n",
    "        features = extract_features(no_car_image_path, fixed_length)\n",
    "        perceptron.train(features, 0)  # Label 0 for not car images\n",
    "        prediction = perceptron.predict(features)\n",
    "        if prediction == 0:\n",
    "            correct_predictions += 1\n",
    "        total_images += 1\n",
    "    \n",
    "    efficiency = correct_predictions / total_images\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    \n",
    "    # Print training progress for each epoch\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "    print(f\"Training time: {training_time:.2f} seconds\")\n",
    "    print(f\"Efficiency: {efficiency:.2f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b467f7a-4e97-4c0b-8ae4-212862d2ecf7",
   "metadata": {},
   "source": [
    "**Training the Data() Version 2**\n",
    "*This saves the model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98521d4d-a761-4258-bb98-d12c5f077e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Training time: 22.91 seconds\n",
      "Efficiency: 0.99\n",
      "\n",
      "Epoch 2/10\n",
      "Training time: 5.66 seconds\n",
      "Efficiency: 0.99\n",
      "\n",
      "Epoch 3/10\n",
      "Training time: 4.54 seconds\n",
      "Efficiency: 1.00\n",
      "\n",
      "Epoch 4/10\n",
      "Training time: 4.45 seconds\n",
      "Efficiency: 1.00\n",
      "\n",
      "Epoch 5/10\n",
      "Training time: 5.23 seconds\n",
      "Efficiency: 1.00\n",
      "\n",
      "Epoch 6/10\n",
      "Training time: 5.86 seconds\n",
      "Efficiency: 1.00\n",
      "\n",
      "Epoch 7/10\n",
      "Training time: 5.12 seconds\n",
      "Efficiency: 1.00\n",
      "\n",
      "Epoch 8/10\n",
      "Training time: 4.99 seconds\n",
      "Efficiency: 1.00\n",
      "\n",
      "Epoch 9/10\n",
      "Training time: 4.45 seconds\n",
      "Efficiency: 1.00\n",
      "\n",
      "Epoch 10/10\n",
      "Training time: 4.25 seconds\n",
      "Efficiency: 1.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import pickle  # Import the pickle library\n",
    "\n",
    "def extract_features(image_path, fixed_length):\n",
    "    # Load the image and resize it to a smaller size\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    image = cv2.resize(image, (64, 128))  # Resize to a smaller size\n",
    "    \n",
    "    # Extract HOG features with reduced dimensionality\n",
    "    hog = cv2.HOGDescriptor((64, 64), (16, 16), (8, 8), (8, 8), 9)\n",
    "    features = hog.compute(image)\n",
    "    \n",
    "    # Convert the tuple to a NumPy array and then flatten\n",
    "    features = np.array(features)\n",
    "    features = features.flatten()\n",
    "    \n",
    "    # Resize features to a fixed length\n",
    "    if len(features) < fixed_length:\n",
    "        features = np.pad(features, (0, fixed_length - len(features)))\n",
    "    elif len(features) > fixed_length:\n",
    "        features = features[:fixed_length]\n",
    "    \n",
    "    return features\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, num_features):\n",
    "        self.weights = np.random.rand(num_features)\n",
    "        self.bias = np.random.rand()\n",
    "    \n",
    "    def predict(self, features):\n",
    "        activation = np.dot(features, self.weights) + self.bias\n",
    "        return 1 if activation > 0 else 0\n",
    "    \n",
    "    def train(self, features, label, learning_rate=0.01):\n",
    "        if len(features) != len(self.weights):\n",
    "            raise ValueError(\"Number of features must match the number of weights\")car_folder\n",
    "        \n",
    "        prediction = self.predict(features)\n",
    "        error = label - prediction\n",
    "        self.weights += learning_rate * error * features\n",
    "        self.bias += learning_rate * error\n",
    "\n",
    "# Path to the training data folders\n",
    "car_folder = \"training/car\"\n",
    "not_car_folder = \"training/car\"\n",
    "\n",
    "# Initialize the perceptron\n",
    "fixed_length = 1000  # Adjust this value based on your needs\n",
    "num_features = fixed_length\n",
    "\n",
    "# Check if a saved model exists, if not, create a new one\n",
    "if os.path.exists(\"perceptron_model.pkl\"):\n",
    "    with open(\"perceptron_model.pkl\", \"rb\") as model_file:\n",
    "        perceptron = pickle.load(model_file)\n",
    "else:\n",
    "    perceptron = Perceptron(num_features)\n",
    "\n",
    "# Training loop\n",
    "epochs = 10  # Adjust the number of epochs as needed\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    correct_predictions = 0\n",
    "    total_images = 0\n",
    "    \n",
    "    for image_name in os.listdir(car_folder):\n",
    "        image_path = os.path.join(car_folder, image_name)\n",
    "        features = extract_features(image_path, fixed_length)\n",
    "        perceptron.train(features, 1)  # Label 1 for car images\n",
    "        prediction = perceptron.predict(features)\n",
    "        if prediction == 1:\n",
    "            correct_predictions += 1\n",
    "        total_images += 1\n",
    "\n",
    "        # Now, switch to a no car image\n",
    "        no_car_image_name = os.listdir(not_car_folder)[total_images % len(os.listdir(not_car_folder))]\n",
    "        no_car_image_path = os.path.join(not_car_folder, no_car_image_name)\n",
    "        features = extract_features(no_car_image_path, fixed_length)\n",
    "        perceptron.train(features, 0)  # Label 0 for not car images\n",
    "        prediction = perceptron.predict(features)\n",
    "        if prediction == 0:\n",
    "            correct_predictions += 1\n",
    "        total_images += 1\n",
    "    \n",
    "    efficiency = correct_predictions / total_images\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "    print(f\"Training time: {training_time:.2f} seconds\")\n",
    "    print(f\"Efficiency: {efficiency:.2f}\\n\")\n",
    "\n",
    "# Save the trained model\n",
    "with open(\"perceptron_model.pkl\", \"wb\") as model_file:\n",
    "    pickle.dump(perceptron, model_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7887eaad-66f4-4f9b-aba2-d054b4517042",
   "metadata": {},
   "source": [
    "**Validating The Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55e8e5f3-0fbe-4cee-840b-74ccccad6553",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil",
    "# Path to the validating data folders (car and not_car)\n",
    "validating_car_folder = \"validating/car\"\n",
    "validating_not_car_folder = \"validating/notcar\"\n",
    "\n",
    "correct_predictions = 0\n",
    "total_images = 0\n",
    "\n",
    "# Create the output directories if they don't exist\n",
    "output_car_folder = \"validating/outputcar\"\n",
    "output_not_car_folder = \"validating/outputnotcar\"\n",
    "os.makedirs(output_car_folder, exist_ok=True)\n",
    "os.makedirs(output_not_car_folder, exist_ok=True)\n",
    "\n",
    "with open(\"validating/answer.txt\", \"w\") as output:\n",
    "    for folder, output_folder in [(validating_car_folder, output_car_folder), (validating_not_car_folder, output_not_car_folder)]:\n",
    "        label = 1 if \"car\" in folder else 0\n",
    "        for image_name in os.listdir(folder):\n",
    "            image_path = os.path.join(folder, image_name)\n",
    "            features = extract_features(image_path, fixed_length)  # Provide fixed_length here\n",
    "            prediction = perceptron.predict(features)\n",
    "            \n",
    "            output.write(f\"Image: {image_name}, Predicted Label: {prediction}\\n\")\n",
    "            \n",
    "            if prediction == label:\n",
    "                correct_predictions += 1\n",
    "                # Move the image to the corresponding output folder\n",
    "                output_image_path = os.path.join(output_folder, image_name)\n",
    "                shutil.copy(image_path, output_image_path)\n",
    "            \n",
    "            total_images += 1\n",
    "\n",
    "    efficiency = correct_predictions / total_images\n",
    "    output.write(f\"Efficiency: {efficiency:.2f}\\n\")\n",
    "    output.write(f\"Weights: {perceptron.weights}\\n\")\n",
    "    output.write(f\"Bias: {perceptron.bias}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c39d14c-31f1-4c1b-9865-2e28b47abb2a",
   "metadata": {},
   "source": [
    "**Testing The Data(via images)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e19a428-b9d0-4010-9df3-3798a746d881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "test_car_folder = \"testing/car\"\n",
    "test_not_car_folder = \"testing/notcar\"\n",
    "output_file = \"testing/answer.txt\"\n",
    "output_car_folder = \"testing/outputcar\"\n",
    "output_not_car_folder = \"testing/outputnotcar\"\n",
    "\n",
    "correct_predictions = 0\n",
    "total_images = 0\n",
    "\n",
    "# Create the output directories if they don't exist\n",
    "os.makedirs(output_car_folder, exist_ok=True)\n",
    "os.makedirs(output_not_car_folder, exist_ok=True)\n",
    "\n",
    "with open(output_file, \"w\") as output:\n",
    "    for folder, output_folder in [(test_car_folder, output_car_folder), (test_not_car_folder, output_not_car_folder)]:\n",
    "        label = 1 if \"car\" in folder else 0\n",
    "        for image_name in os.listdir(folder):\n",
    "            image_path = os.path.join(folder, image_name)\n",
    "            features = extract_features(image_path, fixed_length)  # Provide fixed_length here\n",
    "            prediction = perceptron.predict(features)\n",
    "            \n",
    "            output.write(f\"Image: {image_name}, Predicted Label: {prediction}\\n\")\n",
    "            \n",
    "            if prediction == label:\n",
    "                correct_predictions += 1\n",
    "                # Move the image to the corresponding output folder\n",
    "                output_image_path = os.path.join(output_folder, image_name)\n",
    "                shutil.copy(image_path, output_image_path)\n",
    "            \n",
    "            total_images += 1\n",
    "\n",
    "    efficiency = correct_predictions / total_images\n",
    "    output.write(f\"Efficiency: {efficiency:.2f}\\n\")\n",
    "    output.write(f\"Weights: {perceptron.weights}\\n\")\n",
    "    output.write(f\"Bias: {perceptron.bias}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c11c614-17a9-4a6e-925f-899cf9234690",
   "metadata": {},
   "source": [
    "**Final Function To give Input via Video**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcbb29d0-5e66-4df3-bacf-87d1110877ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import shutil\n",
    "\n",
    "# Input video file\n",
    "input_video_file = \"input2.mp4\"\n",
    "output_car_folder = \"testvideo/outputcar\"\n",
    "output_not_car_folder = \"testvideo/outputnotcar\"\n",
    "output_file = \"testvideo/output.txt\"  # Define the output file\n",
    "\n",
    "# Create the output directories if they don't exist\n",
    "os.makedirs(output_car_folder, exist_ok=True)\n",
    "os.makedirs(output_not_car_folder, exist_ok=True)\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(input_video_file)\n",
    "frame_number = 0\n",
    "\n",
    "# Create a temporary directory to save frames\n",
    "temp_frame_dir = \"test/frames\"\n",
    "os.makedirs(temp_frame_dir, exist_ok=True)\n",
    "\n",
    "with open(output_file, \"w\") as output:\n",
    "    while True:\n",
    "        # Read a frame from the video\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Break the loop if the video has ended\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Save the frame as an image\n",
    "        frame_number += 1\n",
    "        frame_filename = f\"frame_{frame_number:04d}.png\"\n",
    "        frame_path = os.path.join(temp_frame_dir, frame_filename)\n",
    "        cv2.imwrite(frame_path, frame)\n",
    "        \n",
    "        # Check if the frame was successfully saved\n",
    "        if os.path.isfile(frame_path):\n",
    "            # Extract features and predict\n",
    "            features = extract_features(frame_path, fixed_length)  # Provide fixed_length here\n",
    "            prediction = perceptron.predict(features)\n",
    "            \n",
    "            output.write(f\"Frame: {frame_filename}, Predicted Label: {prediction}\\n\")\n",
    "            \n",
    "            # Move the frame to the corresponding output folder\n",
    "            if prediction == 1:\n",
    "                output_image_path = os.path.join(output_car_folder, frame_filename)\n",
    "            else:\n",
    "                output_image_path = os.path.join(output_not_car_folder, frame_filename)\n",
    "            \n",
    "            shutil.copy(frame_path, output_image_path)\n",
    "        else:\n",
    "            print(f\"Failed to save frame: {frame_filename}\")\n",
    "\n",
    "# Release the video capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
